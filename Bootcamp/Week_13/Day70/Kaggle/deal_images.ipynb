{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       path    label     id        img\n",
       "0     train    happy  00007  00007.jpg\n",
       "1     train    happy  00014  00014.jpg\n",
       "2     train    happy  00030  00030.jpg\n",
       "3     train    happy  00034  00034.jpg\n",
       "4     train    happy  00046  00046.jpg\n",
       "...     ...      ...    ...        ...\n",
       "6171  train  sadness  28674  28674.jpg\n",
       "6172  train  sadness  28678  28678.jpg\n",
       "6173  train  sadness  28680  28680.jpg\n",
       "6174  train  sadness  28683  28683.jpg\n",
       "6175  train  sadness  28685  28685.jpg\n",
       "\n",
       "[6176 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n      <th>id</th>\n      <th>img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train</td>\n      <td>happy</td>\n      <td>00007</td>\n      <td>00007.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train</td>\n      <td>happy</td>\n      <td>00014</td>\n      <td>00014.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train</td>\n      <td>happy</td>\n      <td>00030</td>\n      <td>00030.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>happy</td>\n      <td>00034</td>\n      <td>00034.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train</td>\n      <td>happy</td>\n      <td>00046</td>\n      <td>00046.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6171</th>\n      <td>train</td>\n      <td>sadness</td>\n      <td>28674</td>\n      <td>28674.jpg</td>\n    </tr>\n    <tr>\n      <th>6172</th>\n      <td>train</td>\n      <td>sadness</td>\n      <td>28678</td>\n      <td>28678.jpg</td>\n    </tr>\n    <tr>\n      <th>6173</th>\n      <td>train</td>\n      <td>sadness</td>\n      <td>28680</td>\n      <td>28680.jpg</td>\n    </tr>\n    <tr>\n      <th>6174</th>\n      <td>train</td>\n      <td>sadness</td>\n      <td>28683</td>\n      <td>28683.jpg</td>\n    </tr>\n    <tr>\n      <th>6175</th>\n      <td>train</td>\n      <td>sadness</td>\n      <td>28685</td>\n      <td>28685.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>6176 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#PARA CREAR LA COLUMNA PATH\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "path_train = \"train/**/**.jpg\"\n",
    "\n",
    "def make_imag_df(path):\n",
    "    dictionary = {}\n",
    "    for paths in glob.glob(path):\n",
    "        dictionary.setdefault('path', []).append(paths.split('\\\\')[-3])\n",
    "        dictionary.setdefault('label', []).append(paths.split('\\\\')[-2])\n",
    "        dictionary.setdefault('id', []).append(paths.split('\\\\')[-1][:-4])\n",
    "        dictionary.setdefault('img', []).append(paths.split('\\\\')[-1])\n",
    "    images = pd.DataFrame(dictionary)\n",
    "    return images\n",
    "\n",
    "make_imag_df(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2 # opencv, librería de referencia para tratamiento de imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.devrant.com/devrant/rant/r_1688469_xaXLS.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        label  id_img               path\n",
       "0       happy   22373    happy/22373.jpg\n",
       "1       happy   21433    happy/21433.jpg\n",
       "2       happy   12418    happy/12418.jpg\n",
       "3       happy   21278    happy/21278.jpg\n",
       "4       happy    8081    happy/08081.jpg\n",
       "...       ...     ...                ...\n",
       "6171  sadness   11346  sadness/11346.jpg\n",
       "6172  sadness    4441  sadness/04441.jpg\n",
       "6173  sadness   15236  sadness/15236.jpg\n",
       "6174  sadness   27361  sadness/27361.jpg\n",
       "6175  sadness   25239  sadness/25239.jpg\n",
       "\n",
       "[6176 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>id_img</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>happy</td>\n      <td>22373</td>\n      <td>happy/22373.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>happy</td>\n      <td>21433</td>\n      <td>happy/21433.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>happy</td>\n      <td>12418</td>\n      <td>happy/12418.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy</td>\n      <td>21278</td>\n      <td>happy/21278.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>happy</td>\n      <td>8081</td>\n      <td>happy/08081.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6171</th>\n      <td>sadness</td>\n      <td>11346</td>\n      <td>sadness/11346.jpg</td>\n    </tr>\n    <tr>\n      <th>6172</th>\n      <td>sadness</td>\n      <td>4441</td>\n      <td>sadness/04441.jpg</td>\n    </tr>\n    <tr>\n      <th>6173</th>\n      <td>sadness</td>\n      <td>15236</td>\n      <td>sadness/15236.jpg</td>\n    </tr>\n    <tr>\n      <th>6174</th>\n      <td>sadness</td>\n      <td>27361</td>\n      <td>sadness/27361.jpg</td>\n    </tr>\n    <tr>\n      <th>6175</th>\n      <td>sadness</td>\n      <td>25239</td>\n      <td>sadness/25239.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>6176 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"train_set.csv\")\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imágenes están en blanco y negro, pero el método `cv2.imread` necesita que se le especifique el segundo argumento como 0 ya que por defecto leerá en color. \n",
    "\n",
    "`flag: It specifies the way in which image should be read. It’s default value is cv2.IMREAD_COLOR`\n",
    "[para más info...](https://www.geeksforgeeks.org/python-opencv-cv2-imread-method/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "drama = cv2.imread(\"train/happy/00007.jpg\", 0) \n",
    "drama.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b97669b490>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"250.052344pt\" version=\"1.1\" viewBox=\"0 0 251.565 250.052344\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-03-05T11:54:52.939849</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 250.052344 \r\nL 251.565 250.052344 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 226.174219 \r\nL 244.365 226.174219 \r\nL 244.365 8.734219 \r\nL 26.925 8.734219 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p86a1eeb527)\">\r\n    <image height=\"218\" id=\"image93d2ee545f\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-8.174219\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mf750c67ce4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.19\" xlink:href=\"#mf750c67ce4\" y=\"226.174219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(26.00875 240.772656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"74.49\" xlink:href=\"#mf750c67ce4\" y=\"226.174219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(68.1275 240.772656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"119.79\" xlink:href=\"#mf750c67ce4\" y=\"226.174219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(113.4275 240.772656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"165.09\" xlink:href=\"#mf750c67ce4\" y=\"226.174219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(158.7275 240.772656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"210.39\" xlink:href=\"#mf750c67ce4\" y=\"226.174219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(204.0275 240.772656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m8aacd0801a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m8aacd0801a\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m8aacd0801a\" y=\"56.299219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 60.098437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m8aacd0801a\" y=\"101.599219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 105.398437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m8aacd0801a\" y=\"146.899219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m8aacd0801a\" y=\"192.199219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(7.2 195.998437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 226.174219 \r\nL 26.925 8.734219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 226.174219 \r\nL 244.365 8.734219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 226.174219 \r\nL 244.365 226.174219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 8.734219 \r\nL 244.365 8.734219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p86a1eeb527\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"8.734219\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(drama, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "drama.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ten en cuenta que las imágenes no están mezcladas, están primero las fotos felices y luego todas las fotos tristes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "            ...\n",
       "            3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284],\n",
       "           dtype='int64', length=3285)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "train_set[train_set.label == \"happy\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Int64Index([3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294,\n",
       "            ...\n",
       "            6166, 6167, 6168, 6169, 6170, 6171, 6172, 6173, 6174, 6175],\n",
       "           dtype='int64', length=2891)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "train_set[train_set.label == \"sadness\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accedemos a las imágenes directamente en sus carpetas, puedes usar librerías como `glob` o nuestro ya viejo conocido, `os`.\n",
    "Para cargar y mostrar las imágenes `imageio` o como ya hemos visto `cv2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer** Para gestionar imágenes no es necesario cargar los arrays en nuestro jupyter. \n",
    "\n",
    "https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN = np.nan\n",
    "# train_set[\"leer_imagen\"] = NaN\n",
    "\n",
    "# for i in train_set.path:\n",
    "#     train_set[\"leer_imagen\"] = cv2.imread(\"train/\" + i, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'happy/22373.jpg'"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "train_set.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lista = []\n",
    "for i in train_set.path:\n",
    "    x = \"train/\" + i\n",
    "    lista.append(cv2.imread(x, 0))\n",
    "train_set[\"leer_imagen\"] = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        label  id_img               path  \\\n",
       "0       happy   22373    happy/22373.jpg   \n",
       "1       happy   21433    happy/21433.jpg   \n",
       "2       happy   12418    happy/12418.jpg   \n",
       "3       happy   21278    happy/21278.jpg   \n",
       "4       happy    8081    happy/08081.jpg   \n",
       "...       ...     ...                ...   \n",
       "6171  sadness   11346  sadness/11346.jpg   \n",
       "6172  sadness    4441  sadness/04441.jpg   \n",
       "6173  sadness   15236  sadness/15236.jpg   \n",
       "6174  sadness   27361  sadness/27361.jpg   \n",
       "6175  sadness   25239  sadness/25239.jpg   \n",
       "\n",
       "                                            leer_imagen  \n",
       "0     [[25, 44, 56, 68, 88, 98, 93, 92, 105, 120, 13...  \n",
       "1     [[33, 29, 22, 18, 19, 23, 22, 19, 20, 23, 14, ...  \n",
       "2     [[35, 43, 66, 84, 71, 41, 36, 53, 97, 56, 100,...  \n",
       "3     [[118, 124, 132, 126, 127, 139, 67, 38, 33, 29...  \n",
       "4     [[201, 209, 193, 107, 106, 107, 98, 114, 144, ...  \n",
       "...                                                 ...  \n",
       "6171  [[167, 180, 196, 171, 101, 50, 52, 70, 55, 49,...  \n",
       "6172  [[163, 154, 128, 116, 121, 106, 90, 99, 115, 1...  \n",
       "6173  [[109, 25, 29, 33, 55, 65, 82, 87, 147, 179, 1...  \n",
       "6174  [[62, 64, 67, 52, 57, 65, 50, 55, 117, 179, 15...  \n",
       "6175  [[163, 167, 123, 78, 50, 30, 26, 14, 7, 12, 50...  \n",
       "\n",
       "[6176 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>id_img</th>\n      <th>path</th>\n      <th>leer_imagen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>happy</td>\n      <td>22373</td>\n      <td>happy/22373.jpg</td>\n      <td>[[25, 44, 56, 68, 88, 98, 93, 92, 105, 120, 13...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>happy</td>\n      <td>21433</td>\n      <td>happy/21433.jpg</td>\n      <td>[[33, 29, 22, 18, 19, 23, 22, 19, 20, 23, 14, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>happy</td>\n      <td>12418</td>\n      <td>happy/12418.jpg</td>\n      <td>[[35, 43, 66, 84, 71, 41, 36, 53, 97, 56, 100,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy</td>\n      <td>21278</td>\n      <td>happy/21278.jpg</td>\n      <td>[[118, 124, 132, 126, 127, 139, 67, 38, 33, 29...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>happy</td>\n      <td>8081</td>\n      <td>happy/08081.jpg</td>\n      <td>[[201, 209, 193, 107, 106, 107, 98, 114, 144, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6171</th>\n      <td>sadness</td>\n      <td>11346</td>\n      <td>sadness/11346.jpg</td>\n      <td>[[167, 180, 196, 171, 101, 50, 52, 70, 55, 49,...</td>\n    </tr>\n    <tr>\n      <th>6172</th>\n      <td>sadness</td>\n      <td>4441</td>\n      <td>sadness/04441.jpg</td>\n      <td>[[163, 154, 128, 116, 121, 106, 90, 99, 115, 1...</td>\n    </tr>\n    <tr>\n      <th>6173</th>\n      <td>sadness</td>\n      <td>15236</td>\n      <td>sadness/15236.jpg</td>\n      <td>[[109, 25, 29, 33, 55, 65, 82, 87, 147, 179, 1...</td>\n    </tr>\n    <tr>\n      <th>6174</th>\n      <td>sadness</td>\n      <td>27361</td>\n      <td>sadness/27361.jpg</td>\n      <td>[[62, 64, 67, 52, 57, 65, 50, 55, 117, 179, 15...</td>\n    </tr>\n    <tr>\n      <th>6175</th>\n      <td>sadness</td>\n      <td>25239</td>\n      <td>sadness/25239.jpg</td>\n      <td>[[163, 167, 123, 78, 50, 30, 26, 14, 7, 12, 50...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6176 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['sadness', 'happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'leer_imagen'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f00d7e0fd2d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleer_imagen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5140\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5141\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'leer_imagen'"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_set.leer_imagen[i], cmap='gray')\n",
    "    plt.xlabel(class_names[train_set.label[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[\"label\"] = train_set[\"label\"].apply(lambda x: 1 if x == \"happy\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "train_set[\"label\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      label  id_img               path  \\\n",
       "0         0   22373    happy/22373.jpg   \n",
       "1         0   21433    happy/21433.jpg   \n",
       "2         0   12418    happy/12418.jpg   \n",
       "3         0   21278    happy/21278.jpg   \n",
       "4         0    8081    happy/08081.jpg   \n",
       "...     ...     ...                ...   \n",
       "6171      0   11346  sadness/11346.jpg   \n",
       "6172      0    4441  sadness/04441.jpg   \n",
       "6173      0   15236  sadness/15236.jpg   \n",
       "6174      0   27361  sadness/27361.jpg   \n",
       "6175      0   25239  sadness/25239.jpg   \n",
       "\n",
       "                                            leer_imagen  \n",
       "0     [[25, 44, 56, 68, 88, 98, 93, 92, 105, 120, 13...  \n",
       "1     [[33, 29, 22, 18, 19, 23, 22, 19, 20, 23, 14, ...  \n",
       "2     [[35, 43, 66, 84, 71, 41, 36, 53, 97, 56, 100,...  \n",
       "3     [[118, 124, 132, 126, 127, 139, 67, 38, 33, 29...  \n",
       "4     [[201, 209, 193, 107, 106, 107, 98, 114, 144, ...  \n",
       "...                                                 ...  \n",
       "6171  [[167, 180, 196, 171, 101, 50, 52, 70, 55, 49,...  \n",
       "6172  [[163, 154, 128, 116, 121, 106, 90, 99, 115, 1...  \n",
       "6173  [[109, 25, 29, 33, 55, 65, 82, 87, 147, 179, 1...  \n",
       "6174  [[62, 64, 67, 52, 57, 65, 50, 55, 117, 179, 15...  \n",
       "6175  [[163, 167, 123, 78, 50, 30, 26, 14, 7, 12, 50...  \n",
       "\n",
       "[6176 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>id_img</th>\n      <th>path</th>\n      <th>leer_imagen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>22373</td>\n      <td>happy/22373.jpg</td>\n      <td>[[25, 44, 56, 68, 88, 98, 93, 92, 105, 120, 13...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>21433</td>\n      <td>happy/21433.jpg</td>\n      <td>[[33, 29, 22, 18, 19, 23, 22, 19, 20, 23, 14, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>12418</td>\n      <td>happy/12418.jpg</td>\n      <td>[[35, 43, 66, 84, 71, 41, 36, 53, 97, 56, 100,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>21278</td>\n      <td>happy/21278.jpg</td>\n      <td>[[118, 124, 132, 126, 127, 139, 67, 38, 33, 29...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>8081</td>\n      <td>happy/08081.jpg</td>\n      <td>[[201, 209, 193, 107, 106, 107, 98, 114, 144, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6171</th>\n      <td>0</td>\n      <td>11346</td>\n      <td>sadness/11346.jpg</td>\n      <td>[[167, 180, 196, 171, 101, 50, 52, 70, 55, 49,...</td>\n    </tr>\n    <tr>\n      <th>6172</th>\n      <td>0</td>\n      <td>4441</td>\n      <td>sadness/04441.jpg</td>\n      <td>[[163, 154, 128, 116, 121, 106, 90, 99, 115, 1...</td>\n    </tr>\n    <tr>\n      <th>6173</th>\n      <td>0</td>\n      <td>15236</td>\n      <td>sadness/15236.jpg</td>\n      <td>[[109, 25, 29, 33, 55, 65, 82, 87, 147, 179, 1...</td>\n    </tr>\n    <tr>\n      <th>6174</th>\n      <td>0</td>\n      <td>27361</td>\n      <td>sadness/27361.jpg</td>\n      <td>[[62, 64, 67, 52, 57, 65, 50, 55, 117, 179, 15...</td>\n    </tr>\n    <tr>\n      <th>6175</th>\n      <td>0</td>\n      <td>25239</td>\n      <td>sadness/25239.jpg</td>\n      <td>[[163, 167, 123, 78, 50, 30, 26, 14, 7, 12, 50...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6176 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos las X y las y para pasarlas a Tensor\n",
    "X = np.stack(train_set.leer_imagen)\n",
    "y = np.stack(train_set.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_random_state = []\n",
    "lista_accuracy = []\n",
    "lista_epochs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------------------------------------------------------\n",
      "ramdom state is: 80\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "155/155 [==============================] - 3s 11ms/step - loss: 0.0460 - accuracy: 0.0000e+00\n",
      "#################################################\n",
      "Epoch is: 1\n",
      "#################################################\n",
      "39/39 - 0s - loss: 2.0010e-04 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "Epoch 1/2\n",
      "155/155 [==============================] - 2s 11ms/step - loss: 6.5711e-05 - accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "155/155 [==============================] - 2s 12ms/step - loss: 3.7322e-05 - accuracy: 0.0000e+00\n",
      "#################################################\n",
      "Epoch is: 2\n",
      "#################################################\n",
      "39/39 - 0s - loss: 7.3465e-05 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "Epoch 1/3\n",
      "155/155 [==============================] - 2s 10ms/step - loss: 2.3244e-05 - accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "155/155 [==============================] - 2s 10ms/step - loss: 1.3513e-05 - accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "155/155 [==============================] - 2s 10ms/step - loss: 8.5633e-06 - accuracy: 0.0000e+00\n",
      "#################################################\n",
      "Epoch is: 3\n",
      "#################################################\n",
      "39/39 - 0s - loss: 2.2085e-05 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "Epoch 1/4\n",
      "155/155 [==============================] - 2s 11ms/step - loss: 5.7727e-06 - accuracy: 0.0000e+00\n",
      "Epoch 2/4\n",
      "155/155 [==============================] - 2s 11ms/step - loss: 4.0830e-06 - accuracy: 0.0000e+00\n",
      "Epoch 3/4\n",
      "155/155 [==============================] - 2s 10ms/step - loss: 2.9628e-06 - accuracy: 0.0000e+00\n",
      "Epoch 4/4\n",
      "155/155 [==============================] - 2s 11ms/step - loss: 2.1078e-06 - accuracy: 0.0000e+00\n",
      "#################################################\n",
      "Epoch is: 4\n",
      "#################################################\n",
      "39/39 - 0s - loss: 5.7311e-06 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 2s 11ms/step - loss: 1.6601e-06 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 2s 12ms/step - loss: 1.1984e-06 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 2s 12ms/step - loss: 9.2920e-07 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 3s 18ms/step - loss: 9.1984e-07 - accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 3s 19ms/step - loss: 8.3192e-07 - accuracy: 0.0000e+00\n",
      "#################################################\n",
      "Epoch is: 5\n",
      "#################################################\n",
      "39/39 - 0s - loss: 1.9348e-06 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "Epoch 1/6\n",
      "155/155 [==============================] - 3s 17ms/step - loss: 5.6784e-07 - accuracy: 0.0000e+00\n",
      "Epoch 2/6\n",
      "155/155 [==============================] - 2s 15ms/step - loss: 4.6814e-07 - accuracy: 0.0000e+00\n",
      "Epoch 3/6\n",
      "155/155 [==============================] - 2s 15ms/step - loss: 4.3160e-07 - accuracy: 0.0000e+00\n",
      "Epoch 4/6\n",
      "155/155 [==============================] - 2s 15ms/step - loss: 3.4609e-07 - accuracy: 0.0000e+00\n",
      "Epoch 5/6\n",
      "155/155 [==============================] - 2s 13ms/step - loss: 3.2604e-07 - accuracy: 0.0000e+00\n",
      "Epoch 6/6\n",
      "155/155 [==============================] - 2s 13ms/step - loss: 2.6165e-07 - accuracy: 0.0000e+00\n",
      "#################################################\n",
      "Epoch is: 6\n",
      "#################################################\n",
      "39/39 - 0s - loss: 7.5713e-07 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "ramdom state is: 81\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "155/155 [==============================] - 3s 14ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
      "#################################################\n",
      "Epoch is: 1\n",
      "#################################################\n",
      "39/39 - 0s - loss: 1.7231e-04 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "Epoch 1/2\n",
      "155/155 [==============================] - 2s 14ms/step - loss: 1.1923e-04 - accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "155/155 [==============================] - 2s 13ms/step - loss: 6.8162e-05 - accuracy: 0.0000e+00\n",
      "#################################################\n",
      "Epoch is: 2\n",
      "#################################################\n",
      "39/39 - 0s - loss: 5.2265e-05 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "Epoch 1/3\n",
      "155/155 [==============================] - 2s 14ms/step - loss: 4.1392e-05 - accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      " 38/155 [======>.......................] - ETA: 1s - loss: 9.7530e-05 - accuracy: 0.0000e+00"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-750f24c61a00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# Entrenamos el modelo con 10 epochs - ¿¿¿¿EPOCHS????\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#################################################\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch is:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# Variable para meter en un dataframe\n",
    "rdm_state = np.random\n",
    "\n",
    "# Ajustamos las X y las y para pasarlas a Tensor\n",
    "X = np.stack(train_set.leer_imagen)\n",
    "y = np.stack(train_set.label)\n",
    "\n",
    "# Dividimos entre train y test\n",
    "for i in range(80,101):\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"ramdom state is:\", i)\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "    # Hacemos reshape y normalizamos\n",
    "    train_images = train_images.reshape(train_images.shape[0],48,48,1)\n",
    "    train_images = train_images / 255\n",
    "\n",
    "    test_images = test_images.reshape(test_images.shape[0],48,48,1)\n",
    "    test_images = test_images / 255\n",
    "\n",
    "    # Creamos el modelo\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=8, #ESTO SON NEURONAS??\n",
    "                            kernel_size=(2),\n",
    "                            input_shape=(48, 48, 1),\n",
    "                            padding='same'))\n",
    "    model.add(layers.MaxPooling2D()) # Maxpool quedando las imagenes a la mitad (en dimesiones)\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation=\"softmax\"))\n",
    "\n",
    "    # Compilamos el modelo - añadimos otros parametros para su correcto funcionamiento/medición\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    for j in range(1,7):\n",
    "        # Entrenamos el modelo con 10 epochs - ¿¿¿¿EPOCHS????\n",
    "        model.fit(train_images, train_labels, epochs=j)\n",
    "        print(\"#################################################\")\n",
    "        print(\"Epoch is:\", j)\n",
    "        print(\"#################################################\")\n",
    "\n",
    "        # Hacemos una medición del modelo - ¿¿¿¿VERBOSE????\n",
    "        test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "        # Añadimos accuracy y random state a dataframe\n",
    "        lista_accuracy.append(test_acc*100)\n",
    "        lista_random_state.append(i)\n",
    "        lista_epochs.append(j)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     random  epoch   accuracy\n",
       "269      44      6  56.067961\n",
       "268      44      5  56.067961\n",
       "267      44      4  56.067961\n",
       "266      44      3  56.067961\n",
       "265      44      2  56.067961\n",
       "..      ...    ...        ...\n",
       "204      34      1  50.080907\n",
       "206      34      3  50.080907\n",
       "207      34      4  50.080907\n",
       "208      34      5  50.080907\n",
       "205      34      2  50.080907\n",
       "\n",
       "[608 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>random</th>\n      <th>epoch</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>269</th>\n      <td>44</td>\n      <td>6</td>\n      <td>56.067961</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>44</td>\n      <td>5</td>\n      <td>56.067961</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>44</td>\n      <td>4</td>\n      <td>56.067961</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>44</td>\n      <td>3</td>\n      <td>56.067961</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>44</td>\n      <td>2</td>\n      <td>56.067961</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>34</td>\n      <td>1</td>\n      <td>50.080907</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>34</td>\n      <td>3</td>\n      <td>50.080907</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>34</td>\n      <td>4</td>\n      <td>50.080907</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>34</td>\n      <td>5</td>\n      <td>50.080907</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>34</td>\n      <td>2</td>\n      <td>50.080907</td>\n    </tr>\n  </tbody>\n</table>\n<p>608 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"random\": lista_random_state, \"epoch\": lista_epochs, \"accuracy\": lista_accuracy, \"epoch\": lista_epochs})\n",
    "submission.sort_values(\"accuracy\", ascending=False)\n",
    "# random 44 epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = train_images.reshape(1, -1)\n",
    "#train_images = tf.expand_dims(train_images, axis=-1)\n",
    "#test_images = tf.expand_dims(test_images, axis=-1)\n",
    "\n",
    "# train_images = np.expand_dims(train_images, axis = 0)\n",
    "# test_images = np.expand_dims(test_images, axis = 0)"
   ]
  },
  {
   "source": [
    "# MODELO DEFINITIVO\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos las X y las y para pasarlas a Tensor\n",
    "X = np.stack(train_set.leer_imagen)\n",
    "y = np.stack(train_set.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0],48,48,1)\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos reshape y normalizamos\n",
    "train_images = train_images.reshape(train_images.shape[0],48,48,1)\n",
    "train_images = train_images / 255\n",
    "\n",
    "test_images = test_images.reshape(test_images.shape[0],48,48,1)\n",
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=8, #ESTO SON NEURONAS??\n",
    "                        kernel_size=(2),\n",
    "                        input_shape=(48, 48, 1),\n",
    "                        padding='same'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(filters=8, #ESTO SON NEURONAS??\n",
    "                        kernel_size=(2),\n",
    "                        input_shape=(48, 48, 1),\n",
    "                        padding='same'))\n",
    "model.add(layers.MaxPooling2D()) # Maxpool quedando las imagenes a la mitad (en dimesiones)\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='sigmoid'))\n",
    "model.add(layers.Dense(1, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilamos el modelo - añadimos otros parametros para su correcto funcionamiento/medición\n",
    "model.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/6\n",
      "155/155 [==============================] - 3s 14ms/step - loss: 0.2374 - accuracy: 0.0000e+00\n",
      "Epoch 2/6\n",
      "155/155 [==============================] - 2s 12ms/step - loss: 0.0298 - accuracy: 0.0000e+00\n",
      "Epoch 3/6\n",
      "155/155 [==============================] - 2s 14ms/step - loss: 0.0154 - accuracy: 0.0000e+00\n",
      "Epoch 4/6\n",
      "155/155 [==============================] - 2s 16ms/step - loss: 0.0095 - accuracy: 0.0000e+00\n",
      "Epoch 5/6\n",
      "155/155 [==============================] - 3s 17ms/step - loss: 0.0065 - accuracy: 0.0000e+00\n",
      "Epoch 6/6\n",
      "155/155 [==============================] - 3s 16ms/step - loss: 0.0047 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b97865de50>"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# Entrenamos el modelo con 10 epochs - ¿¿¿¿EPOCHS????\n",
    "model.fit(train_images, train_labels, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 1s - loss: 0.0039 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Hacemos una medición del modelo - ¿¿¿¿VERBOSE????\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Predecimos el modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id_img            path\n",
       "0   18341  test/18341.jpg\n",
       "1   13176  test/13176.jpg\n",
       "2   23945  test/23945.jpg\n",
       "3   15968  test/15968.jpg\n",
       "4   18382  test/18382.jpg"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_img</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18341</td>\n      <td>test/18341.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13176</td>\n      <td>test/13176.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23945</td>\n      <td>test/23945.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15968</td>\n      <td>test/15968.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18382</td>\n      <td>test/18382.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "to_pred = pd.read_csv(\"test_set.csv\")\n",
    "to_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for i in to_pred.path:\n",
    "    x = i\n",
    "    lista.append(cv2.imread(x, 0))\n",
    "to_pred[\"leer_imagen\"] = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.stack(to_pred.leer_imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(y_test.shape[0],48,48,1)\n",
    "y_test = y_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "predictions_submit = model.predict(y_test)\n",
    "predictions_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_submit = list(predictions_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        0\n",
       "0     1.0\n",
       "1     1.0\n",
       "2     1.0\n",
       "3     1.0\n",
       "4     1.0\n",
       "...   ...\n",
       "4112  1.0\n",
       "4113  1.0\n",
       "4114  1.0\n",
       "4115  1.0\n",
       "4116  1.0\n",
       "\n",
       "[4117 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4112</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4113</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4114</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4115</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4116</th>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4117 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "predictions_submit = pd.DataFrame(predictions_submit)\n",
    "predictions_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "predictions_submit.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id_img  label\n",
       "0      18341    1.0\n",
       "1      13176    1.0\n",
       "2      23945    1.0\n",
       "3      15968    1.0\n",
       "4      18382    1.0\n",
       "...      ...    ...\n",
       "4112    8966    1.0\n",
       "4113   12111    1.0\n",
       "4114   16629    1.0\n",
       "4115   24322    1.0\n",
       "4116   23412    1.0\n",
       "\n",
       "[4117 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_img</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18341</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13176</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23945</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15968</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18382</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4112</th>\n      <td>8966</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4113</th>\n      <td>12111</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4114</th>\n      <td>16629</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4115</th>\n      <td>24322</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4116</th>\n      <td>23412</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4117 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"id_img\": to_pred[\"id_img\"], \"label\": predictions_submit[0]})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4117 entries, 0 to 4116\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   id_img  4117 non-null   int64  \n 1   label   4117 non-null   float64\ndtypes: float64(1), int64(1)\nmemory usage: 64.5 KB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id_img  label\n",
       "0      18341  happy\n",
       "1      13176  happy\n",
       "2      23945  happy\n",
       "3      15968  happy\n",
       "4      18382  happy\n",
       "...      ...    ...\n",
       "4112    8966  happy\n",
       "4113   12111  happy\n",
       "4114   16629  happy\n",
       "4115   24322  happy\n",
       "4116   23412  happy\n",
       "\n",
       "[4117 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_img</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18341</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13176</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23945</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15968</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18382</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4112</th>\n      <td>8966</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4113</th>\n      <td>12111</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4114</th>\n      <td>16629</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4115</th>\n      <td>24322</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4116</th>\n      <td>23412</td>\n      <td>happy</td>\n    </tr>\n  </tbody>\n</table>\n<p>4117 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "submission[\"label\"] = submission[\"label\"].astype(float)\n",
    "submission[\"label\"] = submission[\"label\"].apply(lambda x: \"happy\" if x == 1.0 else \"sadness\")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "you're ready to submit! :)\n"
     ]
    }
   ],
   "source": [
    "all_ok_to_submit = False\n",
    "if submission.shape == sample.shape:\n",
    "    if submission.columns.all() == sample.columns.all():\n",
    "        if submission.id_img.all() == sample.id_img.all():\n",
    "            submission.to_csv(\"output/to_submit.csv\", index = False)\n",
    "            all_ok_to_submit = True\n",
    "            # ¡¡¡¡¡¡¡ADD INDEX = FALSE!!!!!!!!!\n",
    "\n",
    "if all_ok_to_submit:\n",
    "    print(\"you're ready to submit! :)\")\n",
    "else: \n",
    "    print(\"Sorry...There was an error :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}